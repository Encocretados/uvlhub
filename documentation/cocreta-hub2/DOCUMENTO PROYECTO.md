#  COCRETA-HUB2

# **DOCUMENTO DEL PROYECTO**

# ![Texto alternativo](documentation/cocreta-hub2/img/uvlhub.png)


**Grupo 3**  
**2024/2025**  
**Evolución y Gestión de la Configuración**

**Enlace al repositorio:** https://github.com/Encocretados/uvlhub  
**Sistema desplegado:** https://encocretados.onrender.com/

| Miembro | Implicación |
| :---- | :---- |
| Barrancos Márquez, María | 8 |
| Luna Navarro, Paula | 8.75 |
| Martín Muñoz, Álvaro | 9.5 |
| Noya Cano, Lucía | 8.75 |
| Picón Garrote, Alexander | 9.5 |
| Vázquez Conejo, Álvaro  | 8 |

# 

# 

### **Indicadores del proyecto**

| Miembro del equipo | Horas | Commits | LoC | Test | Issues | Work Item |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| Barrancos Márquez, María | 35 | 10 | 570 | 7 | 3 | **Dashboard**: Un usuario tiene la posibilidad de visualizar métricas clave de la aplicación, facilitando el acceso a información consolidada como número de datasets, usuarios, descargas y otros datos relevantes. **Rate dataset:** Un usuario tiene la posibilidad de valorar un dataset. La valoración total del mismo será la media de todas ellas. |
| Luna Navarro, Paula | 42 | 29 | 2156 | 10 | 4 | **Register developer:** Un usuario tiene la posibilidad de registrarse como un desarrollador, diferenciándolo de un usuario normal **Staging Area:** Los datasets antes de subirse a fakenodo se quedan en un area de stage, y el usuario puede decidir cuando publicarlos  |
| Martín Muñoz, Álvaro | 44 | 26 | 2864 | 12 | 12 | **AI integration:** Se debe implementar la funcionalidad para integrar una inteligencia artificial que haga de asistente de ayuda en el sistema. **Generate Api Token:** Se debe implementar la funcionalidad para generar un access token al iniciar sesión. El access token será utilizado para autenticar y autorizar las solicitudes realizadas por el usuario dentro del sistema.  |
| Noya Cano, Lucía | 40 | 16 | 379 | 7 | 8 | **Register developer:** Un usuario tiene la posibilidad de registrarse como un desarrollador, diferenciándolo de un usuario normal **Staging Area:** Los datasets antes de subirse a fakenodo se quedan en un area de stage, y el usuario puede decidir cuando publicarlos  |
| Picón Garrote, Alexander | 44 | 24 | 1937 | 10 | 6 | **AI integration:** Se debe implementar la funcionalidad para integrar una inteligencia artificial que haga de asistente de ayuda en el sistema. **Generate Api Token:** Se debe implementar la funcionalidad para generar un access token al iniciar sesión. El access token será utilizado para autenticar y autorizar las solicitudes realizadas por el usuario dentro del sistema.  |
| Vázquez Conejo, Álvaro | 37 | 7 | 635 | 7 | 5 | **Dashboard**: Un usuario tiene la posibilidad de visualizar métricas clave de la aplicación, facilitando el acceso a información consolidada como número de datasets, usuarios, descargas y otros datos relevantes.**Rate dataset**: Un usuario tiene la posibilidad de valorar un dataset. La valoración total del mismo será la media de todas ellas. |
| **TOTAL** | **242** | **112** | **8274** | **53** | **38** | Aclaración: Los Work Items desarrollados se han realizado de manera colaborativa por pares |

- Enlace al apartado de **Insights** del proyecto donde se pueden comprobar el número de **commits** y **líneas de código** de cada miembro del equipo: [https://github.com/Encocretados/uvlhub/graphs/contributors](https://github.com/Encocretados/uvlhub/graphs/contributors)  
- Enlace al apartado de **issues** del proyecto donde se pueden observar las diferentes incidencias creadas por cada miembro del equipo: [https://github.com/Encocretados/uvlhub/issues](https://github.com/Encocretados/uvlhub/issues)  
- Enlace a los **test** realizados por el usuario @paulalunanavarro:   
  - [https://github.com/Encocretados/uvlhub/commit/5ebb4b8b7b20d064229b13f6f3b533a83a7bd7f8](https://github.com/Encocretados/uvlhub/commit/5ebb4b8b7b20d064229b13f6f3b533a83a7bd7f8)  
  - [https://github.com/Encocretados/uvlhub/commit/56ca5bf4140d4d92f8a96dff9a469432a8659045](https://github.com/Encocretados/uvlhub/commit/56ca5bf4140d4d92f8a96dff9a469432a8659045)

- Enlace a los **test** realizados por el usuario @lucianoya:  
  - [https://github.com/Encocretados/uvlhub/commit/868bc1d27f5e8a3cc0a33a4dfddfebfc9f5c3a06](https://github.com/Encocretados/uvlhub/commit/868bc1d27f5e8a3cc0a33a4dfddfebfc9f5c3a06)  
  - [https://github.com/Encocretados/uvlhub/commit/99b52b21c15fbb8eb9ae9f326e07b65075ddc5a1](https://github.com/Encocretados/uvlhub/commit/99b52b21c15fbb8eb9ae9f326e07b65075ddc5a1)  
  - [https://github.com/Encocretados/uvlhub/commit/eb45cd51a1f261ccc74b40653824c72b6eb77a62](https://github.com/Encocretados/uvlhub/commit/eb45cd51a1f261ccc74b40653824c72b6eb77a62)  
- Enlace a los **test** realizados por el usuario @alepingar:  
  - [https://github.com/Encocretados/uvlhub/commit/69cd93c61b7a9a924d54556dbbe0713ee8b55709](https://github.com/Encocretados/uvlhub/commit/69cd93c61b7a9a924d54556dbbe0713ee8b55709)  
  - [https://github.com/Encocretados/uvlhub/commit/eb4eb23553541dfa4862cb9d647ec0b11570d762](https://github.com/Encocretados/uvlhub/commit/eb4eb23553541dfa4862cb9d647ec0b11570d762)  
  - [https://github.com/Encocretados/uvlhub/commit/59adfed5b5bdeeb322913a4ac8c7517121be6885](https://github.com/Encocretados/uvlhub/commit/59adfed5b5bdeeb322913a4ac8c7517121be6885)

- Enlace a los **test** realizados por el usuario @AlvaroMartinMunoz:  
   (los 12 tests)  
  -  [https://github.com/Encocretados/uvlhub/blob/main/app/modules/ia/tests/test\_unit\_ia.py](https://github.com/Encocretados/uvlhub/blob/main/app/modules/ia/tests/test_unit_ia.py)

   

La tabla contiene la información de cada miembro del proyecto y el total de la siguiente forma:

* Horas: 242  
* Commits: 112  
* LoC (líneas de código): 8274  
* Test: 53  
* Issues: 38  
* Work Item: AI integration , dashboard , rate dataset, generate api token , staging area y register as developer

### **Integración con otros equipos**

Equipos con los que se ha integrado y los motivos por lo que lo ha hecho y lugar en el que se ha dado la integración:

* **Cocreta-hub1:**  
  * La integración con el equipo cocreta-hub1 se ha llevado a cabo mediante el uso de un repositorio común que sigue un modelo de integración continua. Para garantizar la calidad y la coherencia del desarrollo, hemos adoptado las siguientes prácticas:  
    * **Subida a la rama principal (main):** Todas las funcionalidades desarrolladas por ambos equipos se integran en la rama main únicamente cuando han sido completadas por completo, pasando las pruebas necesarias y verificándose que cumplen con los criterios de aceptación definidos previamente.  
    * **Revisión y pruebas:** Antes de integrar los cambios en main, cada funcionalidad pasa por un proceso de revisión de código y pruebas automáticas. Esto asegura que los cambios realizados no rompan el flujo de trabajo ni afecten negativamente al sistema.  
    * **Lugar de integración:** Este proceso se lleva a cabo en el repositorio común alojado en GitHub, donde ambas partes colaboran activamente.  
  * El motivo principal para esta integración ha sido la necesidad de colaborar en el desarrollo de funcionalidades compartidas, optimizar el flujo de trabajo y asegurar la consistencia en el producto final.


  

**Resumen ejecutivo (800 palabras aproximadamente)**

El proyecto cocreta-hub2, desarrollado por el Grupo 3 en el curso 2024/2025, tiene como objetivo mejorar y expandir un sistema basado en el fork de UVLHub, enfocado en la gestión y distribución de datasets para desarrolladores, investigadores y organizaciones. A través de seis funcionalidades clave, que incluyen la generación de tokens API, integración con Inteligencia Artificial, la creación de un dashboard interactivo, registro de usuarios como desarrolladores, un área de staging para datasets y un sistema de valoración, se busca optimizar la experiencia de los usuarios y fomentar la colaboración en proyectos basados en datos. Este sistema está diseñado para ofrecer herramientas avanzadas que faciliten la manipulación, análisis y calidad de los datos, contribuyendo al avance de la investigación y el desarrollo en diversas áreas.

### **Descripción del sistema (1.500 palabras aproximadamente)**

**Descripción del Sistema**

El proyecto desarrollado consiste en la evolución de un fork de UVLHub, un sistema diseñado para la gestión y distribución de datasets orientados a desarrolladores, investigadores y organizaciones que requieren soluciones avanzadas de manejo de datos. Este desarrollo se estructuró alrededor de seis *work items* principales: **generate API token**, **IAI integration**, **dashboard**, **register as developer**, **staging area** y **rate dataset**. En esta descripción, se abordará el sistema desde un punto de vista funcional y arquitectónico, explicando los componentes, sus funcionalidades, y los cambios realizados en relación con el proyecto original.

### **Descripción Funcional**

#### **1\. Generate API Token**

Este componente permite a los usuarios generar un token de autenticación API único para interactuar con el sistema de forma programática. Esta funcionalidad es crucial para desarrolladores que desean automatizar tareas o integrar UVLHub con otras aplicaciones.

* **Funcionalidad principal**: Generación de un token seguro asociado al perfil del usuario registrado.  
* **Uso**: Los usuarios pueden solicitar un token desde su perfil en el sistema y utilizarlo para acceder a las APIs proporcionadas por UVLHub.  
* **Cambios implementados**:  
  * Se incorporó un flujo de renovación y revocación de tokens.  
  * Uso de un sistema de cifrado avanzado para la generación de tokens, garantizando la seguridad.

#### **2\. IA Integration**

Este módulo integra capacidades de Inteligencia Artificial y Machine Learning al sistema UVLHub, proporcionando herramientas para enriquecer los datasets y optimizar su uso.

* **Funcionalidad principal**: Integración con servicios de IA externos para preprocesamiento y análisis avanzado de datasets.  
* **Uso**: Los usuarios pueden solicitar tareas específicas como la limpieza, etiquetado automático, o generación de metadatos.  
* **Cambios implementados**:  
  * Conexión con APIs externas de IA para facilitar el análisis de datos.  
  * Incorporación de un sistema de logs para rastrear las operaciones realizadas por los modelos de IA.

#### **3\. Dashboard**

El tablero o dashboard ofrece una vista centralizada de la información del sistema, brindando a los usuarios un resumen rápido de su actividad y del estado de sus datasets.

* **Funcionalidad principal**: Visualización de métricas clave, como el uso del sistema, actividad reciente y rendimiento de datasets.  
* **Uso**: Los usuarios acceden al dashboard al iniciar sesión para obtener información general.  
* **Cambios implementados**:  
  * Diseño de un dashboard modular que se adapta a los roles de los usuarios.  
  * Inclusión de gráficos interactivos para una experiencia más intuitiva.

#### **4\. Register as Developer**

Esta funcionalidad permite que los usuarios se registren como desarrolladores, desbloqueando acceso a herramientas y APIs exclusivas.

* **Funcionalidad principal**: Registro de usuarios con rol de desarrollador, permitiendo el acceso a capacidades avanzadas del sistema.  
* **Uso**: Los usuarios completan un formulario para verificar su identidad como desarrolladores y recibir acceso a las funcionalidades avanzadas.  
* **Cambios implementados**:  
  * Proceso automatizado de validación de identidad mediante integración con servicios de verificación.  
  * Incorporación de una capa de seguridad adicional para proteger información sensible de los desarrolladores.

#### **5\. Staging Area**

El área de staging es una zona intermedia donde los datasets son preparados antes de ser publicados en el sistema principal.

* **Funcionalidad principal**: Permitir a los usuarios realizar pruebas, validaciones y modificaciones en sus datasets sin afectar el sistema principal.  
* **Uso**: Los usuarios cargan datasets en el staging area para evaluar su calidad y realizar ajustes antes de su publicación definitiva.  
* **Cambios implementados**:  
  * Desarrollo de herramientas de validación automática para garantizar que los datasets cumplan con los estándares requeridos.  
  * Capacidad de realizar ediciones colaborativas en el staging area.

#### **6\. Rate Dataset**

Esta funcionalidad permite a los usuarios calificar y dejar reseñas sobre los datasets disponibles en el sistema.

* **Funcionalidad principal**: Implementación de un sistema de valoraciones y comentarios para fomentar la retroalimentación comunitaria.  
* **Uso**: Los usuarios evalúan datasets basándose en criterios como calidad, utilidad y documentación.  
* **Cambios implementados**:  
  * Desarrollo de un sistema de notificación para alertar a los propietarios de datasets sobre nuevas valoraciones.  
  * Incorporación de filtros para buscar datasets según su calificación.

### **Descripción Técnica**

#### **Arquitectura General**

El sistema se basa en una arquitectura modular orientada a servicios (SOA), lo que permite una alta escalabilidad y flexibilidad en la incorporación de nuevas funcionalidades. Cada uno de los componentes mencionados se integra mediante APIs REST, garantizando una comunicación rápida y confiable entre los subsistemas.

#### **Componentes Principales**

1. **Backend**:  
   * Implementado en Python con el framework Django, que gestiona la lógica del sistema, la autenticación y la integración con APIs externas.  
   * Base de datos PostgreSQL para almacenar información estructurada como usuarios, datasets, tokens y calificaciones.  
2. **Frontend**:  
   * Construido con React.js, ofreciendo una interfaz de usuario moderna e intuitiva.  
   * Uso de librerías como Chart.js para visualizaciones en el dashboard.  
3. **Seguridad**:  
   * Implementación de JWT (JSON Web Tokens) para la autenticación segura de usuarios y tokens API.  
   * Cifrado de datos sensibles mediante AES-256.  
4. **Integraciones**:  
   * APIs externas para la funcionalidad de IA.  
   * Servicios de validación y verificación de identidad para el registro de desarrolladores.

### **Cambios Desarrollados**

En comparación con la versión original de UVLHub, este proyecto incluyó los siguientes cambios significativos:

1. **Generate API Token**:  
   * Creación de una interfaz intuitiva para gestionar tokens.  
   * Integración de cifrado avanzado para garantizar la seguridad.  
2. **AI Integration**:  
   * Conexión con servicios de IA externos.  
   * Desarrollo de flujos de trabajo para automatizar tareas de preprocesamiento.  
3. **Dashboard**:  
   * Implementación de un dashboard modular adaptable a los diferentes roles de usuario.  
   * Gráficos interactivos para mejorar la experiencia del usuario.  
4. **Register as Developer**:  
   * Sistema de validación automatizada para registro seguro.  
   * Integración con APIs de verificación de identidad.  
5. **Staging Area**:  
   * Creación de herramientas de validación automática.  
   * Capacidad para realizar ediciones colaborativas.  
6. **Rate Dataset**:  
   * Sistema de valoraciones y reseñas con filtros avanzados.  
   * Notificaciones automáticas para los propietarios de datasets.

### **Conclusión**

El desarrollo de este fork de UVLHub ha permitido incorporar funcionalidades clave que mejoran la experiencia de los usuarios y amplían las capacidades del sistema. La modularidad de la arquitectura garantiza la escalabilidad, mientras que los cambios realizados abordan las necesidades específicas de los usuarios avanzados y la comunidad en general. Este proyecto no solo cumple con los objetivos planteados, sino que también sienta las bases para futuras extensiones y mejoras.

### **Visión global del proceso de desarrollo (1.500 palabras aproximadamente)**

El proceso de desarrollo del proyecto se ha basado en un enfoque iterativo y colaborativo, siguiendo principios de metodologías ágiles para garantizar la entrega continua de valor. Este enfoque permitió incorporar cambios rápidamente, adaptarse a nuevas necesidades y mantener un flujo constante de comunicación entre los integrantes del equipo. En este documento se presenta una descripción general del proceso, las herramientas empleadas y un ejemplo concreto de cómo se abordaría un cambio en el sistema, desde su concepción hasta su despliegue en producción.

### **Enfoque Metodológico**

#### **Planificación y Priorización**

El proceso comenzó con la identificación y análisis de los requisitos del proyecto. Se utilizaron herramientas como **Jira** y **Trello** para gestionar el backlog, priorizar tareas y mantener un registro de los *work items*. Estos elementos se dividieron en historias de usuario y tareas específicas, alineadas con los objetivos del proyecto.

#### **Iteración y Desarrollo**

Cada ciclo de desarrollo se organizó en sprints de dos semanas, durante los cuales se realizaron las siguientes actividades clave:

1. **Diseño**: Se definieron las arquitecturas necesarias y se documentaron los requisitos técnicos usando diagramas creados en **Lucidchart**.  
2. **Desarrollo**: Se implementaron las funcionalidades utilizando **Visual Studio Code** y **PyCharm** como entornos de desarrollo. Se empleó **GitHub** para el control de versiones y para facilitar la colaboración entre los integrantes.  
3. **Pruebas**: Las pruebas se automatizaron utilizando **pytest** y se realizaron pruebas manuales en las fases finales de cada sprint.

#### **Validación y Revisión**

Al final de cada sprint, se realizó una revisión de los resultados mediante *demos* internas, en las que se presentó el estado de las funcionalidades implementadas. Además, se realizaron retrospectivas para identificar mejoras en el proceso de trabajo.

### **Herramientas Utilizadas**

El uso de herramientas modernas fue esencial para garantizar la eficiencia y la colaboración en el proyecto. Las principales herramientas utilizadas incluyeron:

* **Jira/Trello**: Para la gestión del backlog y la planificación de sprints.  
* **GitHub**: Como repositorio central y herramienta de integración continua.  
* **Docker**: Para crear entornos de desarrollo replicables y gestionar el despliegue.  
* **SonarQube**: Para garantizar la calidad del código mediante análisis estáticos.  
* **Slack/Zoom**: Para la comunicación y coordinación diaria del equipo.

### **Flujo de Desarrollo**

El proceso de desarrollo se estructuró en las siguientes fases principales:

1. **Análisis de Requisitos**:  
   * Entender las necesidades del usuario y definir claramente los objetivos.  
   * Documentar los requisitos en historias de usuario que incluyan criterios de aceptación claros.  
2. **Diseño de la Solución**:  
   * Crear diagramas arquitectónicos y flujos de trabajo.  
   * Identificar dependencias y riesgos.  
3. **Implementación**:  
   * Dividir las historias en tareas pequeñas.  
   * Desarrollar siguiendo las mejores prácticas, incluyendo pruebas unitarias y revisiones de código mediante *pull requests*.  
4. **Pruebas**:  
   * Automatizar pruebas unitarias y de integración.  
   * Realizar pruebas funcionales para validar los criterios de aceptación.  
5. **Despliegue**:  
   * Usar pipelines de integración y despliegue continuo (CI/CD) en **GitHub Actions**.  
   * Verificar el despliegue en entornos de staging antes de pasar a producción.  
6. **Mantenimiento**:  
   * Monitorear el rendimiento del sistema.  
   * Resolver problemas y gestionar actualizaciones.

### **Ejemplo de un Cambio en el Sistema**

Un ejemplo de cambio propuesto para el sistema es la implementación de una funcionalidad para **exportar datasets en formatos adicionales**. A continuación, se describe cómo se abordaría este cambio siguiendo el ciclo de desarrollo:

#### **1\. Concepción del Cambio**

* **Identificación**: Se detecta que los usuarios desean exportar datasets en formatos como XML y Parquet, además de los formatos actuales (CSV y JSON).  
* **Priorización**: La funcionalidad se evalúa en términos de impacto y esfuerzo, asignándole una prioridad media en el backlog.

#### **2\. Diseño de la Solución**

* Se realiza un análisis para identificar los cambios necesarios en el backend y el frontend.  
* Se crean diagramas de flujo para ilustrar el proceso de exportación.  
* Se documentan las especificaciones técnicas, como los nuevos formatos soportados y los endpoints requeridos.

#### **3\. Implementación**

* **Backend**: Se modifica el servicio de exportación en Django para admitir XML y Parquet. Se actualizan los tests unitarios para cubrir los nuevos formatos.  
* **Frontend**: Se añade una opción en el dashboard para seleccionar los formatos adicionales.

#### **4\. Pruebas**

* Se escriben pruebas unitarias para verificar la generación correcta de los nuevos formatos.  
* Se realizan pruebas funcionales para asegurar que la opción esté disponible en el dashboard y funcione según lo esperado.

#### **5\. Despliegue**

* El cambio se revisa y se fusiona al repositorio principal mediante un *pull request*.  
* Se despliega en el entorno de staging para validación.  
* Finalmente, se lanza a producción utilizando el pipeline CI/CD.

#### **6\. Validación Post-Despliegue**

* Se monitorea el uso de la funcionalidad mediante herramientas de analítica.  
* Se recolecta retroalimentación de los usuarios para identificar posibles mejoras.

### **Reflexión Final**

El proceso de desarrollo implementado garantiza la entrega de funcionalidades de alta calidad mientras se mantiene la flexibilidad para adaptarse a nuevas demandas. Mediante el uso de herramientas y metodologías modernas, el equipo ha podido superar desafíos y entregar un sistema escalable y funcional. Este enfoque continuará evolucionando para abordar futuros retos y maximizar el impacto del sistema en la comunidad.

### **Entorno de desarrollo (800 palabras aproximadamente)**

El entorno de desarrollo utilizado para el proyecto Cocreta-Hub2 está compuesto por varias tecnologías y herramientas que permiten tanto el desarrollo como la gestión del sistema en su totalidad. El sistema Cocreta-Hub2 es una extensión y mejora de UVLHub, que facilita la gestión de datasets y recursos para la comunidad de desarrolladores e investigadores. Este entorno incluye herramientas para la programación en Python, la gestión de bases de datos, la creación de un servidor web y la interacción entre distintos módulos del sistema. A continuación se describe el entorno de desarrollo utilizado, las versiones de las herramientas clave y los pasos necesarios para instalar y configurar el sistema.

**Herramientas Principales y Versiones Utilizadas**

* **Sistema Operativo:** El entorno de desarrollo se realiza bajo un sistema operativo basado en Ubuntu 22.04 LTS o superior. Este sistema es adecuado para el desarrollo con tecnologías como Python, Flask y MariaDB, que son las principales herramientas utilizadas en el proyecto.  
    
* **Lenguaje de Programación:** El lenguaje de programación principal para este proyecto es Python 3.12. Este lenguaje es ampliamente utilizado en desarrollo web y sistemas de backend debido a su simplicidad y versatilidad.  
    
* **Framework Web:** Se utiliza Flask, un framework ligero de Python para la construcción de aplicaciones web. Flask facilita la creación de aplicaciones web modulares y escalables, y es ideal para proyectos como Cocreta-Hub2 que requieren manejar diversas funcionalidades en un solo sistema.  
    
* **Base de Datos:** Para la gestión de datos, el proyecto utiliza MariaDB, un sistema de gestión de bases de datos relacional que es compatible con MySQL y ofrece un rendimiento eficiente para manejar grandes volúmenes de datos.  
    
* **Entorno Virtual:** Para gestionar las dependencias de Python y evitar conflictos con otros proyectos, se emplea un entorno virtual (usando venv), lo que permite mantener las dependencias específicas del proyecto aisladas del resto del sistema.

**Instalación del Sistema y Subsistemas Relacionados**

A continuación se detallan los pasos necesarios para instalar y configurar el sistema Cocreta-Hub2 en un entorno local, asegurando que todas las dependencias y configuraciones sean correctamente aplicadas.

**1\. Actualización del Sistema**  
Es importante mantener el sistema actualizado para evitar posibles incompatibilidades con los paquetes y dependencias del proyecto. Se deben ejecutar los siguientes comandos:

*sudo apt update \-y*  
*sudo apt upgrade \-y*

**2\. Clonar el Repositorio**  
El primer paso para obtener el código fuente del proyecto es clonar el repositorio desde GitHub. Dependiendo de si el proyecto ha sido bifurcado o no, se puede usar una de las siguientes líneas de comando:

*git clone https://github.com/diverso-lab/uvlhub.git*  
*cd uvlhub*

Si se está utilizando un fork personal, se debe clonar el repositorio del fork:

*git clone git@github.com:\<YOUR\_GITHUB\_USER\>/uvlhub\_practicas.git*  
*cd uvlhub\_practicas*

**3\. Instalación de MariaDB**  
MariaDB es la base de datos utilizada para almacenar toda la información relevante para el sistema. Se instala usando el gestor de paquetes apt en Ubuntu:

*sudo apt install mariadb-server \-y*

Una vez instalado, se inicia el servicio de MariaDB:

*sudo systemctl start mariadb*

Es recomendable configurar la base de datos para asegurar la seguridad y funcionalidad. Esto se hace ejecutando el siguiente script de seguridad:

*sudo mysql\_secure\_installation*

Durante este proceso, se establecen las contraseñas y configuraciones iniciales, como la eliminación de usuarios anónimos y la configuración de la contraseña para el usuario root.

**4\. Configuración de la Base de Datos**  
Se deben crear las bases de datos necesarias para el sistema:

*sudo mysql \-u root \-p*  
*CREATE DATABASE uvlhubdb;*  
*CREATE DATABASE uvlhubdb\_test;*  
*CREATE USER 'uvlhubdb\_user'@'localhost' IDENTIFIED BY 'uvlhubdb\_password';*  
*GRANT ALL PRIVILEGES ON uvlhubdb.\* TO 'uvlhubdb\_user'@'localhost';*  
*GRANT ALL PRIVILEGES ON uvlhubdb\_test.\* TO 'uvlhubdb\_user'@'localhost';*  
*FLUSH PRIVILEGES;*  
*EXIT;*

**5\. Instalación de Dependencias Python**  
Para instalar las dependencias necesarias, primero se crea un entorno virtual y luego se activan las dependencias del proyecto. En este caso, se utiliza Python 3.12, por lo que es necesario instalar el paquete de venv:

*sudo apt install python3.12-venv*  
*python3.12 \-m venv venv*  
*source venv/bin/activate*

Después, se actualiza pip y se instalan las dependencias del proyecto:

*pip install \--upgrade pip*  
*pip install \-r requirements.txt*

**6\. Instalación de Rosemary en Modo Editable**  
Rosemary es una herramienta CLI (Command Line Interface) diseñada para facilitar las tareas de gestión del proyecto. Se instala en modo editable para que los cambios realizados en el código se reflejen automáticamente:

*pip install \-e ./*

**7\. Configuración de Variables de Entorno**  
Para que la aplicación se conecte correctamente a la base de datos y otros servicios, es necesario configurar las variables de entorno. Para ello, se crea un archivo .env utilizando un archivo de ejemplo:

*cp .env.local.example .env*

**8\. Migraciones y Población de la Base de Datos**  
Una vez configurado todo, es necesario aplicar las migraciones para crear las tablas y estructuras necesarias en la base de datos:

*flask db upgrade*

Se puede poblar la base de datos con datos de ejemplo para facilitar el desarrollo y la navegación:

*rosemary db:seed*

**9\. Ejecución del Servidor de Desarrollo**  
Finalmente, el servidor de desarrollo se ejecuta usando Flask. Este servidor se ejecutará en el puerto 5000 por defecto:

*flask run \--host=0.0.0.0 \--reload \--debug*

Los flags \--host, \--reload, y \--debug permiten que el servidor sea accesible desde cualquier dispositivo en la red local y se recargue automáticamente cuando se detecten cambios en el código.

**Conclusión**  
El entorno de desarrollo de Cocreta-Hub2 se compone de una combinación de tecnologías robustas y bien soportadas como Python, Flask, MariaDB y herramientas de gestión de contenedores como Docker y Vagrant. La configuración adecuada de estas herramientas garantiza que el sistema funcione de manera eficiente y escalable. Seguir los pasos de instalación detallados asegura que todos los miembros del equipo puedan trabajar con el mismo entorno y puedan contribuir al desarrollo del proyecto sin problemas.

### **Ejercicio de propuesta de cambio: Modificación del texto del botón "Publicar Dataset" a "Subir Dataset"**

En este ejercicio se aborda una propuesta de cambio sencillo pero representativo de la evolución y gestión de la configuración de un proyecto. El cambio consiste en modificar el texto de un botón en la interfaz de usuario del sistema, específicamente cambiar "Publicar Dataset" por "Subir Dataset". Aunque se trata de un ajuste menor, sigue un proceso detallado que incluye análisis del impacto, implementación, pruebas y despliegue.

El primer paso consiste en identificar el cambio necesario y analizar su impacto. En este caso, el texto del botón afecta únicamente al frontend, dentro del componente encargado de gestionar las interacciones del usuario con los datasets. Este componente se encuentra en el directorio del frontend del proyecto. 

Para comenzar la implementación, se clona el repositorio desde GitHub utilizando el comando git clone, y se instala el entorno necesario con npm install. Una vez configurado el entorno, se crea una nueva rama de trabajo llamada change-button-text con el comando git checkout \-b change-button-text, siguiendo las buenas prácticas de control de versiones para mantener la trazabilidad del cambio.

A continuación, se localiza el archivo del componente donde está definido el botón. Esto se realiza con una búsqueda en el código utilizando herramientas como grep, buscando la cadena "Publicar Dataset". Este proceso identifica que el archivo afectado es, por ejemplo, **src/components/DatasetForm.jsx.** Con el archivo localizado, se edita el código para cambiar el texto del botón. Originalmente, el botón está definido como **\<button\>{t('Publicar Dataset')}\</button\>,** y se modifica a **\<button\>{t('Subir Dataset')}\</button\>**. Si el proyecto utiliza internacionalización, también se actualizan los archivos de traducción como src/locales/es.json, asegurando que el nuevo texto esté reflejado en todos los idiomas soportados.

Una vez realizados los cambios, se procede a probar el sistema. Se ejecuta el entorno local de desarrollo con npm start, lo que permite verificar en el navegador que el botón muestra el texto actualizado. Además, se realizan pruebas funcionales para asegurarse de que el botón sigue cumpliendo su propósito original sin afectar otras funcionalidades del sistema. Si el proyecto incluye pruebas automatizadas, estas se ejecutan con npm test para confirmar que el cambio no ha introducido errores.

Finalizadas las pruebas, el cambio se registra en el sistema de control de versiones. Se añaden los archivos modificados al área de preparación con git add, y se realiza un commit descriptivo con git commit \-m "fix(dataset): change button text from 'Publicar Dataset' to 'Subir Dataset'". Posteriormente, se suben los cambios al repositorio remoto con git push origin change-button-text, y se crea una Pull Request en GitHub. Este paso permite que otros miembros del equipo revisen el cambio antes de integrarlo en la rama principal (main).

Una vez aprobada la Pull Request, los cambios se fusionan con la rama principal, y, si el sistema cuenta con un pipeline de integración y despliegue continuo (CI/CD), el cambio se despliega automáticamente en producción. Finalmente, se verifica en el entorno de producción que el botón muestra el texto "Subir Dataset", y que todas las funcionalidades asociadas siguen operando correctamente.

Este ejercicio ilustra un proceso completo de evolución y gestión de la configuración, desde la identificación del cambio hasta su despliegue. Aunque se trata de una modificación sencilla, sigue un enfoque riguroso para garantizar la calidad y estabilidad del sistema, alineándose con las mejores prácticas de desarrollo de software colaborativo.

### **Conclusiones y trabajo futuro**

El desarrollo del proyecto ha logrado cumplir con los objetivos principales planteados, incluyendo la implementación de funcionalidades clave como la generación de tokens API, la integración con sistemas de IA, y un dashboard modular que optimiza la experiencia de los usuarios. Estas mejoras han consolidado un sistema más robusto, flexible y orientado a las necesidades específicas de los desarrolladores y la comunidad en general.

Entre los principales logros se destacan:

* La integración exitosa de herramientas de Inteligencia Artificial, que mejora las capacidades de análisis y procesamiento de los datasets.  
* La creación de un área de staging que permite a los usuarios realizar pruebas y validaciones sin impactar el sistema principal.  
* Un sistema de valoraciones que fomenta la retroalimentación comunitaria, promoviendo la colaboración y el crecimiento del ecosistema de datos.

Sin embargo, también se identificaron áreas que pueden beneficiarse de mejoras futuras, demostrando que el proyecto tiene un gran potencial para seguir evolucionando.

### **Trabajo Futuro**

De cara al futuro, se proponen varias líneas de mejora que podrían implementarse en el próximo curso:

1. **Ampliación de las funcionalidades de la integración de IA**:  
   * Desarrollar capacidades de análisis predictivo basadas en machine learning.  
   * Incorporar herramientas para la detección automática de anomalías en los datasets.  
2. **Optimización del área de staging**:  
   * Habilitar un control de versiones avanzado para gestionar cambios realizados en los datasets.  
   * Incorporar una funcionalidad para pruebas automatizadas de los datasets dentro del área de staging.  
3. **Expansión del sistema de valoraciones**:  
   * Implementar métricas adicionales para calificar datasets, como facilidad de uso o calidad de la documentación.  
   * Permitir interacciones más dinámicas entre usuarios, como responder a reseñas o sugerir mejoras directamente a los propietarios.  
4. **Mejoras en el sistema de seguridad**:  
   * Incorporar autenticación multifactorial (MFA) para proteger el acceso a las cuentas y datos sensibles.  
   * Realizar auditorías regulares de seguridad para identificar y mitigar posibles vulnerabilidades.  
5. **Desarrollo de nuevas APIs**:  
   * Crear APIs específicas para la búsqueda avanzada de datasets según parámetros personalizados.  
   * Habilitar una API para generar reportes automáticos basados en el uso del sistema.  
6. **Soporte internacional y accesibilidad**:  
   * Traducir la interfaz a varios idiomas para ampliar el alcance del sistema.  
   * Garantizar que el sistema cumpla con estándares de accesibilidad, como WCAG, para usuarios con discapacidades.

Estas propuestas permitirían consolidar el sistema como una plataforma líder en la gestión de datasets, promoviendo la innovación y la colaboración en una comunidad global. Además, el enfoque en la escalabilidad y la seguridad asegura que el sistema estará preparado para enfrentar los retos del futuro.

